.# Creating a FrameWork : ğŸš€ğŸ“š

A FrameWork or Template will Standardize the approaches & steps followed in a real-world **ML & DS** project. ğŸ“ŠğŸ”

We will get in detail ML & DS Framework.

We will majorly follow the projects approach, learning by doing projects. ğŸ‘¨â€ğŸ’»ğŸ—ï¸

## ML &  Data Science Framework : ğŸ¤–ğŸ“š


<img src="images/ML_Framework.png" width=80%>

## **1. Problem Identification :** ğŸ¯
* What category of problem we are dealing with ?? ğŸ¤”
* What Actual Problem we have to tackle ? ğŸ¤¨

#### At First, we must understand the problem or even it need Machine Learning to be solved?? â“
Choose a Simple hand-coded Systems if you can. ğŸ‘¨â€ğŸ’»

Use ML only if the problem is hard to explain in instruction steps. ğŸ§ 

#### Understand the Problem & try to map it with most common ML Problems, try to categorize them among the following common problems. ğŸ”

1. **Supervised Learning :** In these problems, we have the data with required inputs and mapped outputs to them. 

    Based on this multiple **inputs -> Output** pairs the ML Algorithm tries different patterns until it gets the same output in the training data then it completes it's training. ğŸ”„
    
    ### It has mainly 2 types of subproblem: ğŸ“‹

    **A. Classification :** It tends to Classify things into different classes/categories. Simply tells the "input" belongs from this type or another. ğŸ—‚ï¸
    
    They are further divided based on the number of classes to predict.

    **B. Regression :** It typically predicts a **number**, based on other variables the target would represent how much value. ğŸ“‰

    It quantifies all variables to predict the numerical value of target.

2. **Unsupervised Learning :** By the name, these problems contain data that is unlabelled, we don't know what to predict!. ğŸ¤·â€â™‚ï¸

That way we directly understand the patterns in data, commonalities in the data points and then we label them acc. to our need.

#### This Problems contain following common problems: ğŸ—ƒï¸

**A. Clustering :** Creating different groups of data based on their similarities.

**B. Association rule Mining :** It understands the frequency of pairs of data points, by getting this combinations of data points. It provides the necessary associations & relations among data points.


3. **Transfer Learning :** It is the type of learning which is transferred from a pre-trained model.

    It's used in case when we know, we can use Learnings by previous models to make our new model excellent. This Learnings from one model is **transferred** to another model. ğŸ”„

4. **Reinforced Learning :** When we want our machine to master one thing based on its wins & losses, we give it rewards if it does something good, else we punish it. 
   
    This way machine try to maximize the reward and learns to do the best for maximum rewards. ğŸ®ğŸ†


## **2. Data** ğŸ“ŠğŸ“ˆ

* Understand what kind of **Data** we have? ğŸ¤”

Looking broadly, data may come in various different formats. ğŸ“ğŸ“

The main two types are: **Structured & Unstructured.** ğŸ“ŠğŸ“„

* **Structured Data:** The data that follows a particular schema or structures. ğŸ—‚ï¸

    Like CSV files, Table data, excel & google sheets etc. ğŸ“‹ğŸ“Š

* **Unstructured Data:** Data that doesn't show any common structures, it can come in several formats. ğŸ“ğŸš«ğŸ—‚ï¸

    Like Audio, Video Files, transcribed audios, Images etc. ğŸµğŸ¥ğŸ“¸

#### Also Data may differ in types based on their collection or velocity. Like: âš¡ğŸ“…

* **Static Data:** The data which remains the same and doesn't change so frequently. i.e. Historical Data for Analysis. ğŸ“†ğŸ“ˆ

* **Streaming Data:** Data which changes so frequently and needs continuous updates. The Data which is used in a prediction which requires live data. i.e. **Daily News Data for Stock Prediction.** ğŸ—ï¸ğŸ“Š

## **3. Evaluation (Goal) :** ğŸ¯ğŸ“ˆ

* What Success means for us? ğŸ†ğŸ’¡
* What result we want from our project? ğŸš€ğŸ”

We have to get a rough idea about what we expect from our model, how accurate results we want. ğŸ“ŠğŸ§ 

This must not be exact a numerical value. **Evaluation** may change based on the data we have & the conditions we face throughout our analysis. ğŸ”„ğŸ“ˆ

Common Evaluation metrics are given below that are used to check a model's performance: ğŸ“ğŸ“Š

<img src="images/Eval_metric.png" width=80%> ğŸ“ŠğŸ“‰

* We will learn all of them later! ğŸ“šğŸ”œ

## **4. Features in Data:** ğŸ“ŠğŸ“‹

Features refer to the variables or properties of data that are used to predict the target variable. ğŸ¯ğŸ“ˆ

They are also called independent variables used in ML models to predict target/independent variables. ğŸ”ğŸ§ 

**Feature Engineering:** When we figure out what features to use, transform existing features, or create new features. Means the overall process of getting features ready for our project is called Feature Engineering. ğŸ› ï¸ğŸ“Š

#### Types of Features: ğŸ“ğŸ”¢

There are mainly 2 types of features: 

**1. Numerical (Quantitative):** These are the features consisting of numerical values. ğŸ”¢ğŸ“ˆ

**2. Categorical (Qualitative):** The features which denote few categories of a value. i.e. **True/False, Male/Female, or Country names** etc. ğŸ“ŠğŸ—‚ï¸

**Derived Features:** The features created by ourselves based on existing available features, or modified existing features are called Derived Features. ğŸ”„ğŸ› ï¸

* Good & Efficient Features are very important to build good ML Models. ğŸ‘ğŸ†
* A particular Feature must be in a large number of records to be considered as Features. ğŸ’¡ğŸ“Š
## **5. Data/ML Modelling :** ğŸ› ï¸ğŸ¤–

The Modelling process in ML refers to the overall steps taken in the finalization of a ML Model or ML Algorithm used. ğŸ“ˆğŸ¤–

This Modeling contains crucial steps like:

* We process data for creating models, Splitting data into train, test sets is called Data **Modelling** ğŸ“ŠğŸ”

1. **Choosing the Right model :** Choose right, relatable model to be used. The **Training Data Set** is used to train this. ğŸ¯ğŸ”§
   
2. **Tuning/Improving the model :** We validate our model, whether it's considerable or not, we Fine tune it until it meets content requirements. **Normally 10-15% of original data is used to validate.** ğŸ”„ğŸ”ğŸ’»
   
3. **Test & Compare the Model :** After validating the Model is tested & Evaluated on a **Test DataSet (10-15% of original data)**. Different Models are compared at Test Stage to find the Best. ğŸ“ğŸ”ğŸ“Š

### Generally, we split the Actual Data into 2 parts only.
#### i.e. Training & Testing Data. ğŸ“ŠğŸ”

#### In Training & Testing models, we can face multiple problems Like OverFitting & UnderFitting. ğŸ“‰ğŸ“ˆ

Poor performance on the training data means the model hasnâ€™t learned properly and is **underfitting**. Try a different model, improve the existing one through hyperparameter or collect more data. ğŸ“‰ğŸ“ğŸ”§

* UnderFitting can occur due to **"Data Mismatch"** of Training & Test Sets.
* Or the less amount of Training data doesn't provide many patterns to ML model for learning.

Great performance on the training data but poor performance on the test data means your model doesnâ€™t generalize well. Your model may be **overfitting** the training data. Try using a simpler model or making sure your test data is of the same style your model is training on. ğŸ“ˆğŸ“ğŸ¤–

* OverFitting can occur due to **"Data Leakage"** from testing to training sets. (Improper Splitting of DataSet)
* OverFitting can occur due to a complex model that learns too many patterns & always predicts pretty much the same as training data.

#### Fixes to Under & Over Fittings. ğŸ”§ğŸ“‰ğŸ“ˆ
<img src="images/fixes.png" width=80%>

## **6. Experimentation :** ğŸ§ªğŸ“Š

* What we have tried? is it good? ğŸ¤”ğŸ‘
* What else we can try? ğŸ¤”ğŸ”

In Experimentation, we just try to look more different ways to improve our model, by doing experiments, changing some processes, we can make our model more efficient. ğŸ’¡ğŸ”¬

---
## Data Science WorkFlow : ğŸ“ŠğŸ”ğŸ§¹ğŸ”„

A common Data Science WorkFlow contains many of the ML Framework Components.
Instead All of it is Data Science (We are making use of Data!!)

Data Collection, Cleaning, transforming, Data Splitting, and getting data ready for Model comes under Data Science WorkFlow. ğŸ“ŠğŸ§¹ğŸ”„

In Previous Steps: **Data, Evaluation & Features** we will be using Data Science tools & methods.

## The Following Tools we will use in our projects majorly.

<img src="images/tools.png" width=70%>
<img src="images/tools2.png" width=70%>